{"cells":[{"cell_type":"markdown","metadata":{"id":"67RBrvkUviuj"},"source":["<a href=\"https://www.inove.com.ar\"><img src=\"https://raw.githubusercontent.com/InoveAlumnos/dataset_analytics_python/master/images/PA%20Banner.png\" width=\"1000\" align=\"center\"></a>\n","\n","\n","# Ejercicio de clasificación con redes neuronales (antes Random Forest)\n","\n","Ejemplo de clasificación utilizando redes neuronales para la clasificación de drogadas que debería tomar un pasiente según su historial clínico<br>\n","\n","v1.1"]},{"cell_type":"markdown","metadata":{"id":"teh--0vN-lhU"},"source":["### Objetivos: \n","*   Preprocesar los datos (descarga, lectura, limplieza y filtrado).\n","*   Conocer la estructura e implementación de las redes neuronales para clasificación binaria en el caso de asignación de drogas para pacientes.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"y2sSeyEovSw-"},"outputs":[],"source":["#Librerias a implementar\n","import os\n","import platform\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import pandas as pd\n","\n","import tensorflow as tf\n","from tensorflow.keras.utils import to_categorical\n","import keras\n","from keras.models import Sequential\n","from keras.utils import to_categorical"]},{"cell_type":"markdown","metadata":{"id":"7Szo7P_3v00C"},"source":["# Recolectar datos\n","<img src=\"https://raw.githubusercontent.com/InoveAlumnos/dataset_analytics_python/master/images/Pipeline1.png\" width=\"1000\" align=\"middle\">"]},{"cell_type":"markdown","metadata":{"id":"2ZHlNw6f_Kzd"},"source":["### Código de descarga del dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HnVpNGuAvyFi"},"outputs":[],"source":["if os.access('drug200.csv', os.F_OK) is False:\n","    if platform.system() == 'Windows':\n","        !curl https://raw.githubusercontent.com/InoveAlumnos/dataset_analytics_python/master/drug200.csv > drug200.csv\n","    else:\n","        !wget drug200.csv https://raw.githubusercontent.com/InoveAlumnos/dataset_analytics_python/master/drug200.csv"]},{"cell_type":"markdown","metadata":{"id":"BbNSgxdfw0ix"},"source":["### `drug200.csv`:\n","El dataset **`drug200.csv`** contiene diferentes tipos de drogas que se le dan a pacientes relativo a su historial clínico. El objetivo es dado un nuevo paciente clasificarlo y determinar que droga es la más apropiada para el.<br> [Dataset source](https://www.kaggle.com/jeevanrh/drug200csv)\n","\n","- **Age** --> edad, ejemplo 25\n","- **Sex** --> género, ejemplo F(femenino), M(masculino)\n","- **BP (Blood Pressure)** --> presión arterial, ejemplo HIGH(alta)\n","- **Cholesterol** --> colesterol, ejemplo normal (NORMAL)\n","- **Na / k** --> concentración de sodio/potasio en sangre, ejemplo 7.8\n","- **Drug** --> droga suministrada, ejemplo drugC"]},{"cell_type":"markdown","metadata":{"id":"NHHsGe1Qypde"},"source":["# Procesar datos\n","<img src=\"https://raw.githubusercontent.com/InoveAlumnos/dataset_analytics_python/master/images/Pipeline2.png\" width=\"1000\" align=\"middle\">"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uvzaKBMbyoiy"},"outputs":[],"source":["# Una vez descargado el archivo en Colab.\n","# Leerlo con Pandas y el método read_csv\n","# Una vez extraida toda la información se almacena en df\n","# A partir de df y el método describe(), mostrará la descripción estadistica básica del archivo que se guardará en des\n","# Crear una fila nueva llamada Nan en el DataFrame  des,\n","# que indica la cantidad de datos tipo Nan que tiene cada columna.\n","# Para crear una nueva fila, se utilizará el operador loc, donde se indica el nombre\n","# de la nueva fila y con que valores se completará.\n","# La información será de los datos faltantes df.isna().sum()\n","# Crear una fila nueva llamada %Nan en el DataFrame des,\n","# Esta fila se completará con los porcentajes de Nan encontrados en cada columna.\n","\n","df = pd.read_csv(\"drug200.csv\")\n","des = df.describe()\n","des.loc['Nan'] = df.isna().sum()\n","des.loc['%Nan'] = (df.isna().mean())*100\n","des"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Cw9HbE88y3wu"},"outputs":[],"source":["# Muestra las 5 primeras filas del DataFrame df\n","df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LirgXKpiy8dr"},"outputs":[],"source":["# Cantidad de filas y columnas con shape\n","# En la ubicación 0 corresponde a las filas\n","print('Cantidad de datos en observacion:', df.shape[0])"]},{"cell_type":"markdown","metadata":{"id":"0BnzYdlRzBxz"},"source":["# Explorar datos\n","<img src=\"https://raw.githubusercontent.com/InoveAlumnos/dataset_analytics_python/master/images/Pipeline3.png\" width=\"1000\" align=\"middle\">"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yH6oDykAzBMG"},"outputs":[],"source":["# Exploramos que tan balanceado está el dataset,\n","# en cuantos casos se suministró cada droga\n","df['Drug'].value_counts()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"u5cQJRWdzTk3"},"outputs":[],"source":["# Graficar la frecuencia de cada droga\n","# sns, alias de Seaborn\n","# Método .countplot(), para mostrar un gráfico de barras (de frecuencia)\n","# Necesita definir la data y el nombre de la columna que se representará en el eje de las 'x' ('Drug')\n","sns.countplot(data=df, x=\"Drug\")\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"YqVWUXPm0op-"},"source":["Se puede observar que en la mayoría de los casos se suministra la drogaY oa la drogaX, es muy probable que el modelo siga esta tendencia"]},{"cell_type":"markdown","metadata":{"id":"ZdfLMthm0yyY"},"source":["#### Transformar variables categóricas texto a clases numeradas"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GJlDmX_F1ksA"},"outputs":[],"source":["# Se hace una copia de \"df\" en \"df_cod\"\n","df_cod = df.copy()\n","\n","# Se aplica una función lambda para transformar la categorías de la columna \"Drug\"\n","# Crea una columna llamada \"DrugY\" en el DataFrame df_cod. Para representar la droga más dada (drugY) con el número 1 y las demás con 0\n","df_cod['DrugY'] = df_cod['Drug'].apply(lambda x: 1 if x == 'drugY' else 0)\n","\n","# Elimina la columna anterior 'Drug'\n","# axis=1 para que se elimine por filas\n","df_cod = df_cod.drop('Drug', axis=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Lqa4Qq9dEGzr"},"outputs":[],"source":["# Muestra las 5 primeras filas del DataFrame df_cod\n","df_cod.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KKM3d-0Hp7KL"},"outputs":[],"source":["# Graficar la frecuencia de cada drogaY con respecto a las demás\n","# sns, alias de Seaborn\n","# Método .countplot(), para mostrar un gráfico de barras (de frecuencia)\n","# Necesita definir la data y el nombre de la columna que se representará en el eje de las 'x' ('DrugY')\n","sns.countplot(data=df_cod, x=\"DrugY\")\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"n-Y-eHwV08v3"},"outputs":[],"source":["# Se importa la herramienta LabelEncoder de la librería sklearn.preprocessing\n","# Se importa la herramienta OneHotEncoder de la librería sklearn.preprocessing\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.preprocessing import OneHotEncoder\n","\n","\n","def one_hot_encoding(df, column):\n","  ''' Función que recibe un DataFrame y el nombre de una columna\n","      para asignarle un labelEncoder a los datos de la columna,\n","      y así transformar a  OneHotEncoder, para luego obtener un nuevo DataFrame\n","      númerico '''\n","    \n","  # Hace una copia\n","  df_copy = df.copy()\n","  \n","  # LabelEncoder\n","  le = LabelEncoder()\n","  label_encoding = le.fit_transform(df_copy[column])\n","  \n","  # OneHotEncoder\n","  onehot_encoder = OneHotEncoder(sparse=False)\n","  one_hot_encoding = onehot_encoder.fit_transform(label_encoding.reshape(-1, 1))\n","\n","  # Crear las columnas con el resultado del encoder\n","  one_hot_encoding_df = pd.DataFrame(one_hot_encoding, columns=le.classes_, dtype=int)\n","\n","  # Agregar sufijo\n","  one_hot_encoding_df = one_hot_encoding_df.add_prefix(column+'_')\n","\n","  # Unir nuevas columnas al dataset\n","  df_copy = df_copy.join(one_hot_encoding_df)\n","\n","  # Eleminar vieja columna del dataset\n","  df_copy = df_copy.drop([column], axis=1)\n","  return df_copy, le, onehot_encoder\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-mXf8mxK2qps"},"outputs":[],"source":["# Se invoca a la función en tres oportunidades para transformar \n","# a las columnas: 'Sex','BP' y 'Cholesterol'\n","df_cod, le_sex, ohe_sex = one_hot_encoding(df_cod, 'Sex')\n","df_cod, le_bp, ohe_bp = one_hot_encoding(df_cod, 'BP')\n","df_cod, le_colest, ohe_colest = one_hot_encoding(df_cod, 'Cholesterol')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JcMF3cQq3NHC"},"outputs":[],"source":["# Muestra las 5 primeras filas del DataFrame df_cod\n","df_cod.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nnTURxKwNMgV"},"outputs":[],"source":["# displot(), esta función brinda acceso a varios enfoques para visualizar la distribución de datos.\n","# Fuente: https://seaborn.pydata.org/generated/seaborn.displot.html\n","# sns, alias de Seaborn\n","# Necesita la data y el nombre de la columna a representar\n","sns.displot(data=df_cod, x='Age')\n","\n","# Muestra la figura\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-56fTNGsb0-4"},"outputs":[],"source":["# displot(), esta función brinda acceso a varios enfoques para visualizar la distribución de datos.\n","# Fuente: https://seaborn.pydata.org/generated/seaborn.displot.html\n","# sns, alias de Seaborn\n","# Necesita la data y el nombre de la columna a representar\n","sns.displot(data=df_cod, x='Na_to_K')\n","\n","# Muestra la figura\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"A7R9Byh-fkVJ"},"outputs":[],"source":["# Se hace una copia (df_norm)  del DataFrame df_cod\n","df_norm = df_cod.copy()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IyIzTou_N5S_"},"outputs":[],"source":["# Es importante normalizar los datos, ya que las redes funcionan con el proceso\n","# del gradiente descendente.\n","# Como \"Age\" no sigue una distribucion normal y \"Na_to_K\" no parece tener outliers\n","# utilizaremos el MinMaxScaler\n","\n","# Se importa MinMaxScaler de la librería sklearn.preprocessing \n","from sklearn.preprocessing import MinMaxScaler\n","\n","# Se crea el objeto scaler a partir de la clase MinMaxScaler()\n","scaler = MinMaxScaler()\n","\n","# Del DataFrama df_norm se implementa el operador .loc para editar las columnas 'Age', 'Na_to_K'\n","# Para acceder a las columnas se utiliza los corchetes\n","# Los dos puntos (:) indican que se editarán todas las filas de la columna indicada\n","# Para normalizar se utilizá el objeto creado scaler\n","# y el método .fit_transform, que se encargará de normalizar\n","# Entre paréntesis se indica el nombre de la columna del DataFrame. Ej:df_norm[['Age']]\n","df_norm.loc[:, 'Age'] = scaler.fit_transform(df_norm[['Age']])\n","df_norm.loc[:, 'Na_to_K'] = scaler.fit_transform(df_norm[['Na_to_K']])\n","\n","# Observar las  5 primeras filas\n","df_norm.head()"]},{"cell_type":"markdown","metadata":{"id":"7z_SuZlj3gbQ"},"source":["# Entrenar modelo\n","<img src=\"https://raw.githubusercontent.com/InoveAlumnos/dataset_analytics_python/master/images/Pipeline4.png\" width=\"1000\" align=\"middle\">"]},{"cell_type":"markdown","metadata":{"id":"ntY84fHj3q5q"},"source":["El primer paso es obtener los datos que serán la entrada del sistema (X) y los datos que serán la salida del modelo estimador (y)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EIg2_OQ43fqZ"},"outputs":[],"source":["# Se separan los valores para X e y con el método .values\n","# Para los valores de X se mantienen la mayoria de las columnas a excepción de la columna 'drug'\n","# axis=1, parámetro para indicar que se elimine fila a fila\n","# y representará la columna objetivo, que es la columna que contiene las categorías conocidas para cada fila, que el la columna 'drug'\n","X = df_norm.drop('DrugY', axis=1).values\n","y = df_norm['DrugY'].values"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"una-T7TrhiFS"},"outputs":[],"source":["# Entrada a la red neuronal\n","# El [1] indica que solo toma en cuenta el número de columnas --> 9\n","in_shape = X.shape[1] \n","\n","# Salida a la red neuronal\n","# Es 1, ya que obtendremos un resultado; será uno (DrugY) ó cero (otra droga)\n","out_shape = 1"]},{"cell_type":"markdown","metadata":{"id":"sbr-SnON4LuM"},"source":["Siguiente paso es dividir el dataset en entrenamiento (train) y evaluación (test). Utilizaremos el criterio 80%20%"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BVD4YkjS4MW2"},"outputs":[],"source":["# Se importa la herramienta de sklearn.model_selectionl como train_test_split\n","from sklearn.model_selection import train_test_split\n","\n","# Fijamos un \"random_state\" constante para que siempre el dataset se parta de la misma forma\n","# para poder repetir los ensayos\n","# Ojo! Los dataset de train y test son array numpy\n","# Se importa la herramienta de la libreria  train_test_split()\n","# Necesita los valores de X e y\n","# test_size=0.2, permite indicar el porcentaje de valores para validar, equivalente a un 20%\n","# random_state=42,  es un número fijo que utilizan comunmente en documentación, significa que para cada ejecución del algoritmo \n","#se genere nuevos valores aleatorios\n","# y los conjuntos de datos de entrenamiento y pruebas serán diferentes.\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"O4jEl5aRW-Ug"},"outputs":[],"source":["# Se importa Dense de la librería tensorflow.keras.layers\n","from keras.layers import Dense\n","\n","def create_model(input_size, hidden_neurons, output_size):\n","  '''Función que recibe en input_size las entradas a la red (cantidad de columnas),\n","  hidden_neurons (cantidad de neuronas) y output_size (salida de la red). Esta \n","  función tiene el objetivo crea un model con redes neuronales para clasificación'''\n","  # Se crea el objeto model2 a partir de la clase Sequential()\n","  model = Sequential()\n","\n","  # Crear la capa de entrada y la capa oculta (hidden) de la red, que tendrá:\n","  # --> tantas entradas (input_shape) como columnas (input_size)\n","  # --> tantas neuronas como deseemos\n","  # --> utilizamos \"sigmoid\" como capa de activación\n","  model.add(Dense(units=hidden_neurons, activation='sigmoid', input_shape=(input_size,)))\n","\n","  # Crear la capa de salida, que tendrá tantas neuronas como salidas posibles\n","  model.add(Dense(units=output_size, activation='sigmoid'))\n","\n","  return model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tVMeyIyIXgfI"},"outputs":[],"source":["# Se invoca a la función que se encarga de crear el modelos con los valores pasados.\n","model = create_model(in_shape, 64, out_shape)\n","\n","# Configuración del modelo para el entrenamiento, implementando el método compile a partir del modelo creado.\n","# Se necesita indicar los parámetros:\n","# optimizer, nombre del optimizador (es el algoritmo que se encarga del descenso de gradiente estocástico)\n","# Fuente: https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adam\n","# loss, se llama función de pérdida, representa las categorías conocidas de las predicción. Al ser 'binary_crossentropy' la predicción tiene \n","# una salida con dos opciones.\n","# metrics, se define la métrica que evaluará el modelo durante el entrenamiento y las pruebas.\n","# learning_rate, tasa de aprendizaje. El valor predeterminado es 0,001.\n","model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.005),\n","              loss='binary_crossentropy',\n","              metrics=['accuracy'])\n","\n","\n","# Se entrena el modelo con el método fit\n","# Necesita definir los valores para X_train, y_train sumado a la cantidad de épocas que seria la iteraciones de entrenamiento y el porcentaje\n","# dirigido a validación (validation_split=0.2)\n","# batch_size, tamaño del lote a entrenar.\n","history = model.fit(X_train, y_train, validation_split=0.2 , epochs=50, batch_size=32)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kkb1Zw-ac_S9"},"outputs":[],"source":["# Variable epocas_conteo, que almacena en una lista la cantidad de épocas de train\n","# history, es la variable que almacena las predicciones del modelo\n","# y de ella se puede acceder a información como su historial (history) del accuracy\n","epocas_conteo= range(1, len(history.history['accuracy']) + 1)\n","\n","# De Seaborn (sns) se accede al gráfico de línea para representar;\n","# Por un lado, el 'accuracy',\n","# Por el otro, la validación (val_accuracy)\n","sns.lineplot(x=epocas_conteo,  y=history.history['accuracy'], label='train')\n","sns.lineplot(x=epocas_conteo,  y=history.history['val_accuracy'], label='valid')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"P99GMrH-dles"},"outputs":[],"source":["# Variable que almacena las probabilidades de las predicciones\n","# con los datos de evaluación\n","y_hat_prob = model.predict(X_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rk0hTqVnlgzi"},"outputs":[],"source":["# Para los resultados de las predicciones del modelo, \n","# Se aplica una nueva  asignación de valores \n","# Para aquellas probabilidades mayores a 0.5 se cambia a 1\n","# y las demás a 0\n","y_hat = [1 if x >= 0.5 else 0 for x in y_hat_prob]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"m0Bmczmddm--"},"outputs":[],"source":["# De model creado se puede acceder al sumario que muestra la estructura del modelo\n","model.summary()"]},{"cell_type":"markdown","metadata":{"id":"w3IfjUuI4XnD"},"source":["# Validar modelo\n","<img src=\"https://raw.githubusercontent.com/InoveAlumnos/dataset_analytics_python/master/images/Pipeline5.png\" width=\"1000\" align=\"middle\">"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tzBGdQS67eAq"},"outputs":[],"source":["# Calcular la exactitud (accuracy)\n","scores = model.evaluate(X_test, y_test)\n","\n","# Se toma el valor de la ubicación número 1, ya que corresponde al valor de la métrica\n","# Para la ubicación cero, corresponde al error, valor de pérdida.\n","# Fuente: https://www.tensorflow.org/api_docs/python/tf/keras/Model#evaluate\n","scores[1]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CMKONtv55zL8"},"outputs":[],"source":["# Calcular la exactitud (accuracy)\n","from sklearn.metrics import accuracy_score\n","accuracy_score(y_test, y_hat, normalize=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TeLeYLYz6ZhO"},"outputs":[],"source":["# Se utiliza la matriz de confusión para evaluar la precisión de una clasificación.\n","from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n","\n","# Necesita dos variables que contengan los valores a comparar\n","cm = confusion_matrix(y_test, y_hat)\n","\n","# Código para realizar la representación gráfica con los resultados\n","# Se crea la varible cmd, que almacena visualization de la Confusion Matrix \n","# Necesita la variable cm que contiene los resultados de la comparación entre los valores reales y predicción\n","# display_labels, se especifica las etiquetas de las categorias que se evalúan.\n","cmd = ConfusionMatrixDisplay(cm, display_labels=['NOT_Y', 'Y'])\n","\n","# Con cmd.plot se especifica el mapa de colores reconocido por matplotlib.\n","cmd.plot(cmap=plt.cm.Reds)\n","\n","# Mostrar la figura\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"L31cbMxRoUF6"},"source":["# Utilizar modelo\n","<img src=\"https://raw.githubusercontent.com/InoveAlumnos/dataset_analytics_python/master/images/Pipeline6.png\" width=\"1000\" align=\"middle\">"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jCXMEvdMo-lb"},"outputs":[],"source":["df_norm.head()\n","# ¿Cuáles serían los datos de entrada?\n","# Age,\tNa_to_K,\tSex,\tBP,\tCholesterol"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"q3XtMGqmofRj"},"outputs":[],"source":["# Datos de prueba\n","# Se construye el DataFrame\n","prueba = pd.DataFrame({'Age':[39],'Na_to_K':[28.452],'Sex':['F'], 'BP':['HIGH'], 'Cholesterol':['HIGH']})\n","prueba"]},{"cell_type":"markdown","metadata":{"id":"8HkBbgScAJ-W"},"source":["### Los datos tienen que someterse al mismo tratamiento que tuvieron los datos antes del entrenamiento:\n","* Label Encoder\n","* OneHotEnder\n","* Construir un dataframe para los valores transformados\n","* Agregar sufijo\n","* Unir el nuevo dataframe con el anterior\n","* Eliminar la anterior columna de tipo \"strings\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XOZ7mmO9tWp9"},"outputs":[],"source":["# Aplica el label encoder\n","le_sex_prueba = le_sex.transform(prueba['Sex'])\n","\n","# Aplica el one hot encoder\n","sex_ohe_prueba = ohe_sex.transform(le_sex_prueba.reshape(-1, 1))\n","\n","# Se construye el dataframe con los valores del onehotencoder\n","df_sex_prueba = pd.DataFrame(sex_ohe_prueba, columns=le_sex.classes_, dtype=int)\n","\n","# Agregar sufijo\n","df_sex_prueba = df_sex_prueba.add_prefix('Sex'+'_')\n","\n","# Unir nuevas columnas al dataset\n","df_unificado1 = prueba.join(df_sex_prueba)\n","\n","# Eliminar la columna con los datos strings del dataframe\n","df_unificado1 = df_unificado1.drop('Sex', axis=1)\n","df_unificado1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hNmyhCGR7tD1"},"outputs":[],"source":["le_bp_prueba = le_bp.transform(prueba['BP'])\n","ohe_bp_prueba = ohe_bp.transform(le_bp_prueba.reshape(-1, 1))\n","df_bp_prueba = pd.DataFrame(ohe_bp_prueba, columns=le_bp.classes_, dtype=int)\n","# Agregar sufijo\n","df_bp_prueba = df_bp_prueba.add_prefix('BP'+'_')\n","# Unir nuevas columnas al dataset\n","df_unificado2 = df_unificado1.join(df_bp_prueba)\n","df_unificado2 = df_unificado2.drop('BP', axis=1)\n","df_unificado2"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xJdSW1lU73ol"},"outputs":[],"source":["colesterol_le_prueba = le_colest.transform(prueba['Cholesterol'])\n","colesterol_ohe_prueba = ohe_colest.transform(colesterol_le_prueba.reshape(-1, 1))\n","df_colesterol_prueba = pd.DataFrame(colesterol_ohe_prueba, columns=le_colest.classes_, dtype=int)\n","# Agregar sufijo\n","df_colest_prueba = df_colesterol_prueba.add_prefix('Cholesterol'+'_')\n","# Unir nuevas columnas al dataset\n","df_unificado3 = df_unificado2.join(df_colest_prueba)\n","df_unificado3 = df_unificado3.drop('Cholesterol', axis=1)\n","df_unificado3"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VuJUGDdd-rYm"},"outputs":[],"source":["# Definir los datos para X_prueba con el .values\n","X_prueba = df_unificado3.values\n","X_prueba"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Pv57GtEO-44e"},"outputs":[],"source":["# Utilizar el modelo con .predict() y los datos de prueba\n","prediccion = model.predict(X_prueba)\n","prediccion1 = np.argmax(prediccion,axis=1)\n","prediccion1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6QVjCLaa_i7m"},"outputs":[],"source":["resultado = [1 if x >= 0.5 else 0 for x in prediccion]\n","resultado\n","# Si el resultado es 1 = DrugY y si es 0= otra droga"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.7"},"vscode":{"interpreter":{"hash":"97e12f1ac9f26099b54b9e7d4ebc9834a88f2d401bac5ba802dc7f7f5939f7f3"}}},"nbformat":4,"nbformat_minor":0}
