{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3_clasificacion_multiple.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "67RBrvkUviuj"
      },
      "source": [
        "<a href=\"https://www.inove.com.ar\"><img src=\"https://raw.githubusercontent.com/InoveAlumnos/dataset_analytics_python/master/images/PA%20Banner.png\" width=\"1000\" align=\"center\"></a>\n",
        "\n",
        "\n",
        "# Ejercicio de clasificación con redes neuronales (antes KNN)\n",
        "\n",
        "Ejemplo de clasificación utilizando redes neuronales para la clasificación de drogadas que debería tomar un pasiente según su historial clínico<br>\n",
        "\n",
        "v1.1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y2sSeyEovSw-"
      },
      "source": [
        "import os\n",
        "import platform\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "#from keras.utils import to_categorical  \n",
        "from keras.utils.np_utils import to_categorical # Si esto no funciona, probar con el import anterior"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Szo7P_3v00C"
      },
      "source": [
        "# Recolectar datos\n",
        "<img src=\"https://raw.githubusercontent.com/InoveAlumnos/dataset_analytics_python/master/images/Pipeline1.png\" width=\"1000\" align=\"middle\">"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HnVpNGuAvyFi"
      },
      "source": [
        "if os.access('Telecust1.csv', os.F_OK) is False:\n",
        "    if platform.system() == 'Windows':\n",
        "        !curl https://raw.githubusercontent.com/InoveAlumnos/dataset_analytics_python/master/Telecust1.csv > Telecust1.csv\n",
        "    else:\n",
        "        !wget Telecust1.csv https://raw.githubusercontent.com/InoveAlumnos/dataset_analytics_python/master/Telecust1.csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BbNSgxdfw0ix"
      },
      "source": [
        "### `Telecust1.csv.csv`:\n",
        "El dataset **`Telecust1.csv.csv`** contiene diferentes tipos de clientes que consumen un servicio de telecomunicación, los cuales deseamos clasificar en 4 categorias.<br> [Dataset source](https://www.kaggle.com/prathamtripathi/customersegmentation)\n",
        "\n",
        "- **region** --> region, ejemplo 2\n",
        "- **tenure** --> grado permanencia, ejemplo 40\n",
        "- **age** --> edad, ejemplo 52\n",
        "- **income** --> ingresos o sueldo, ejemplo 50 (un número que no representa una moneda real\n",
        "- **marital** --> si está casado o no\n",
        "- **address** --> dirección\n",
        "- **employ** --> empleo\n",
        "- **retire** --> si está retirado o no\n",
        "- **genero** --> 0 o 1 (no se sabe cual es cual)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NHHsGe1Qypde"
      },
      "source": [
        "# Procesar datos\n",
        "<img src=\"https://raw.githubusercontent.com/InoveAlumnos/dataset_analytics_python/master/images/Pipeline2.png\" width=\"1000\" align=\"middle\">"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uvzaKBMbyoiy"
      },
      "source": [
        "df = pd.read_csv(\"Telecust1.csv\")\n",
        "des = df.describe()\n",
        "des.loc['Nan'] = df.isna().sum()\n",
        "des.loc['%Nan'] = (df.isna().mean())*100\n",
        "des"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cw9HbE88y3wu"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LirgXKpiy8dr"
      },
      "source": [
        "print('Cantidad de datos en observacion:', df.shape[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0BnzYdlRzBxz"
      },
      "source": [
        "# Explorar datos\n",
        "<img src=\"https://raw.githubusercontent.com/InoveAlumnos/dataset_analytics_python/master/images/Pipeline3.png\" width=\"1000\" align=\"middle\">"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2w_eW5QI-hf"
      },
      "source": [
        "df.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yH6oDykAzBMG"
      },
      "source": [
        "# Exploramos que tan balanceado está el dataset,\n",
        "# como está repartida las categorias entre los clientes actuales\n",
        "df['custcat'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u5cQJRWdzTk3"
      },
      "source": [
        "ax = sns.countplot(data=df, x=\"custcat\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YqVWUXPm0op-"
      },
      "source": [
        "Se puede ver que el dataset está bastante balanceado, no habrá una tendencia marcada"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6f1b4PBcJAWU"
      },
      "source": [
        "# Nos quedamos con aquellas columnas que podemos entender su relacion con el objetivo\n",
        "df_clean = df[['tenure', 'age', 'income', 'marital', 'retire', 'gender', 'custcat']]\n",
        "df_clean"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZdfLMthm0yyY"
      },
      "source": [
        "#### Normalización de los datos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nqEKDZw0KETM"
      },
      "source": [
        "Analizar cual es la distribución de los datos numéricos\n",
        "- tenure\n",
        "- age\n",
        "- income"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GJlDmX_F1ksA"
      },
      "source": [
        "sns.displot(data=df_clean, x='age')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_X2CcMqdJ7z6"
      },
      "source": [
        "sns.displot(data=df_clean, x='tenure')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9xCksVi5J_V2"
      },
      "source": [
        "sns.displot(data=df_clean, x='income')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7d6BDobHKLHy"
      },
      "source": [
        "El \"ingreso\" sigue una distribución normal pero con muchos outliers, es por eso que no utilizaremos el MinMaxScaler sino que se utilizará el StandardScaler a pesar de que \"tenure\" no siga una distribución normal"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zc6xNfbgKj4y"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "df_norm = df_clean.copy()\n",
        "age_scaler = StandardScaler()\n",
        "tenure_scaler = StandardScaler()\n",
        "income_scaler = StandardScaler()\n",
        "df_norm.loc[:, 'age'] = age_scaler.fit_transform(df[['age']])\n",
        "df_norm.loc[:, 'tenure'] = tenure_scaler.fit_transform(df[['tenure']])\n",
        "df_norm.loc[:, 'income'] = income_scaler.fit_transform(df[['income']])\n",
        "df_norm.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9aODNf0SoPyK"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "df_enc = df_norm.copy()\n",
        "# Reemplazar la columna de salida texto a números\n",
        "df_enc['custcat'] = le.fit_transform(df_enc['custcat'])\n",
        "# Clases identificados\n",
        "le.classes_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7z_SuZlj3gbQ"
      },
      "source": [
        "# Entrenar modelo\n",
        "<img src=\"https://raw.githubusercontent.com/InoveAlumnos/dataset_analytics_python/master/images/Pipeline4.png\" width=\"1000\" align=\"middle\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ntY84fHj3q5q"
      },
      "source": [
        "El primer paso es obtener los datos que serán la entrada del sistema (X) y los datos que serán la salida del modelo estimador (y)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EIg2_OQ43fqZ"
      },
      "source": [
        "X = df_enc.drop('custcat', axis=1).values\n",
        "y = to_categorical(df_enc['custcat'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yUMai--jtV6l"
      },
      "source": [
        "in_shape = X.shape[1]\n",
        "in_shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54jBNa7qtXgz"
      },
      "source": [
        "out_shape = y.shape[1]\n",
        "out_shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sbr-SnON4LuM"
      },
      "source": [
        "Siguiente paso es dividir el dataset en entrenamiento (train) y evaluación (test). Utilizaremos el criterio 80%20%"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BVD4YkjS4MW2"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "# Fijamos un \"random_state\" constante para que siempre el dataset se parta de la misma forma\n",
        "# para poder repetir los ensayos\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fu1u9JhXq9Dy"
      },
      "source": [
        "from keras.layers import Dense\n",
        "\n",
        "def create_model(in_shape, hidden_neurons, out_shape):\n",
        "    # Crear un modelo secuencial\n",
        "    model = Sequential()\n",
        "\n",
        "    # Crear la capa de entrada y la capa oculta (hidden) de la red, que tendrá:\n",
        "    # --> tantas entradas (in_shape) como columnas\n",
        "    # --> tantas neuronas como deseemos\n",
        "    # --> utilizamos \"sigmoid\" como capa de activación\n",
        "    model.add(Dense(units=hidden_neurons, activation='sigmoid', input_shape=(in_shape,)))\n",
        "\n",
        "    # Crear la capa de salida, que tendrá tantas neuronas como salidas posibles\n",
        "    model.add(Dense(units=out_shape, activation='softmax'))\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_89g3dSm2wf"
      },
      "source": [
        "model = create_model(in_shape, 16, out_shape)\n",
        "\n",
        "model.compile(optimizer=\"Adam\",\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(X_train, y_train, validation_split=0.2 , epochs=50, batch_size=32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xDuagYJHvNlm"
      },
      "source": [
        "epoch_count = range(1, len(history.history['accuracy']) + 1)\n",
        "sns.lineplot(x=epoch_count,  y=history.history['accuracy'], label='train')\n",
        "sns.lineplot(x=epoch_count,  y=history.history['val_accuracy'], label='valid')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NL0_TMz7Em4o"
      },
      "source": [
        "y_hat_prob = model.predict(X_test)\n",
        "y_hat = np.argmax(y_hat_prob,axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eUqp47r5hOCv"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w3IfjUuI4XnD"
      },
      "source": [
        "# Validar modelo\n",
        "<img src=\"https://raw.githubusercontent.com/InoveAlumnos/dataset_analytics_python/master/images/Pipeline5.png\" width=\"1000\" align=\"middle\">"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HnXeXHwdyHVx"
      },
      "source": [
        "# Calcular la exactitud (accuracy)\n",
        "#scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "scores = model.evaluate(X_test, y_test)\n",
        "scores[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CMKONtv55zL8"
      },
      "source": [
        "# Calcular la exactitud (accuracy)\n",
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_score(y_test.argmax(axis=1), y_hat, normalize=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TeLeYLYz6ZhO"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "cm = confusion_matrix(y_test.argmax(axis=1), y_hat)\n",
        "cmd = ConfusionMatrixDisplay(cm, display_labels=le.classes_)\n",
        "cmd.plot(cmap=plt.cm.Blues)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9dZxGbjG96jR"
      },
      "source": [
        "# Utilizar modelo\n",
        "<img src=\"https://raw.githubusercontent.com/InoveAlumnos/dataset_analytics_python/master/images/Pipeline6.png\" width=\"1000\" align=\"middle\">"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6euFUIFDRbmP"
      },
      "source": [
        "# Supongamos que deseamos ver a que categoría pertenecemos\n",
        "# dado los siguientes datos\n",
        "age = 25\n",
        "tenure = 4\n",
        "income = df['income'].mean() # ganamos el promedio\n",
        "marital = 0 # no estamos casados\n",
        "retire = 0 # no estamos retirados\n",
        "gender = 1 # solo algun genero"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e01cqkzTS8n3"
      },
      "source": [
        "# El scaler espera como entrada una matriz (filas y columnas)\n",
        "# Por eso el doble corchete\n",
        "age_numpy = np.array([[age]])\n",
        "# Utilizamos float para convertir la matriz que retorna el scaler\n",
        "# a un número\n",
        "age_norm = float(age_scaler.transform(age_numpy))\n",
        "tenure_norm = float(tenure_scaler.transform(np.array([[tenure]])))\n",
        "income_norm = float(income_scaler.transform(np.array([[income]])))\n",
        "# El sistema espera como entrada \"X\" en este caso una sola fila pero varias\n",
        "# columnas, por eso el reshape(1, -1) donde el \"-1\" significa \"varias\"\n",
        "# (el sistema determina cuantas)\n",
        "X_prueba = np.array([tenure_norm, age_norm, income_norm, marital, retire, gender]).reshape(1, -1)\n",
        "print('Shape:', X_prueba.shape)\n",
        "print('Valores:\\n', X_prueba)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IYimWR0FTwK-"
      },
      "source": [
        "mi_categoria_probabilidades = model.predict(X_prueba)\n",
        "mi_categoria_probabilidades"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AybAYTtOFy7t"
      },
      "source": [
        "mi_categoria_dict = dict(zip(le.classes_, mi_categoria_probabilidades.flatten()))\n",
        "mi_categoria_dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kd57KsgVGRsj"
      },
      "source": [
        "mi_categoria_ordenadas = sorted(mi_categoria_dict.items(), key=lambda x: x[1], reverse=True)\n",
        "for categoria in mi_categoria_ordenadas:\n",
        "    print(f'Grado de pertenencia a la categoria {categoria[0]}: {categoria[1]*100:.1f}%')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DMMzBQugHNiM"
      },
      "source": [
        "category = le.inverse_transform((mi_categoria_probabilidades.argmax(),))\n",
        "category"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QUmJ7tFUHuG7"
      },
      "source": [
        "category[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h7yzVZcZ9-4m"
      },
      "source": [
        "# Conclusión\n",
        "<img src=\"https://raw.githubusercontent.com/InoveAlumnos/dataset_analytics_python/master/images/Pipeline7.png\" width=\"1000\" align=\"middle\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sWAReOgo-B7b"
      },
      "source": [
        "En este ejemplo se obtuvo muy poca performance, pero se obtuvo un mejor resultado que la vez que se aplicado el algoritmo de clasificación KNN en donde el accuracy obtenido fue del 34%"
      ]
    }
  ]
}