{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2_clasificacion_binaria.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "67RBrvkUviuj"
      },
      "source": [
        "<a href=\"https://www.inove.com.ar\"><img src=\"https://raw.githubusercontent.com/InoveAlumnos/dataset_analytics_python/master/images/PA%20Banner.png\" width=\"1000\" align=\"center\"></a>\n",
        "\n",
        "\n",
        "# Ejercicio de clasificación con vecinos cercanos (KNN)\n",
        "\n",
        "Ejemplo de clasificación utilizando vecinos cercanos para la clasificación de clientes y determinar que servicio ofrecerle a cada uno<br>\n",
        "\n",
        "v1.1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y2sSeyEovSw-"
      },
      "source": [
        "import os\n",
        "import platform\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "#from keras.utils import to_categorical  \n",
        "from keras.utils.np_utils import to_categorical # Si esto no funciona, probar con el import anterior"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Szo7P_3v00C"
      },
      "source": [
        "# Recolectar datos\n",
        "<img src=\"https://raw.githubusercontent.com/InoveAlumnos/dataset_analytics_python/master/images/Pipeline1.png\" width=\"1000\" align=\"middle\">"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HnVpNGuAvyFi"
      },
      "source": [
        "if os.access('drug200.csv', os.F_OK) is False:\n",
        "    if platform.system() == 'Windows':\n",
        "        !curl https://raw.githubusercontent.com/InoveAlumnos/dataset_analytics_python/master/drug200.csv > drug200.csv\n",
        "    else:\n",
        "        !wget drug200.csv https://raw.githubusercontent.com/InoveAlumnos/dataset_analytics_python/master/drug200.csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BbNSgxdfw0ix"
      },
      "source": [
        "### `drug200.csv`:\n",
        "El dataset **`drug200.csv`** contiene diferentes tipos de drogas que se le dan a pacientes relativo a su historial clínico. El objetivo es dado un nuevo paciente clasificarlo y determinar que droga es la más apropiada para el.<br> [Dataset source](https://www.kaggle.com/jeevanrh/drug200csv)\n",
        "\n",
        "- **Age** --> edad, ejemplo 25\n",
        "- **Sex** --> género, ejemplo F(femenino), M(masculino)\n",
        "- **BP (Blood Pressure)** --> presión arterial, ejemplo HIGH(alta)\n",
        "- **Cholesterol** --> colesterol, ejemplo normal (NORMAL)\n",
        "- **Na / k** --> concentración de sodio/potasio en sangre, ejemplo 7.8\n",
        "- **Drug** --> droga suministrada, ejemplo drugC"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NHHsGe1Qypde"
      },
      "source": [
        "# Procesar datos\n",
        "<img src=\"https://raw.githubusercontent.com/InoveAlumnos/dataset_analytics_python/master/images/Pipeline2.png\" width=\"1000\" align=\"middle\">"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uvzaKBMbyoiy"
      },
      "source": [
        "df = pd.read_csv(\"drug200.csv\")\n",
        "des = df.describe()\n",
        "des.loc['Nan'] = df.isna().sum()\n",
        "des.loc['%Nan'] = (df.isna().mean())*100\n",
        "des"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cw9HbE88y3wu"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LirgXKpiy8dr"
      },
      "source": [
        "print('Cantidad de datos en observacion:', df.shape[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0BnzYdlRzBxz"
      },
      "source": [
        "# Explorar datos\n",
        "<img src=\"https://raw.githubusercontent.com/InoveAlumnos/dataset_analytics_python/master/images/Pipeline3.png\" width=\"1000\" align=\"middle\">"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yH6oDykAzBMG"
      },
      "source": [
        "# Exploramos que tan balanceado está el dataset,\n",
        "# en cuantos casos se suministró cada droga\n",
        "df['Drug'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u5cQJRWdzTk3"
      },
      "source": [
        "ax = sns.countplot(data=df, x=\"Drug\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YqVWUXPm0op-"
      },
      "source": [
        "Se puede observar que en la mayoría de los casos se suministra la drogaY oa la drogaX, es muy probable que el modelo siga esta tendencia"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZdfLMthm0yyY"
      },
      "source": [
        "#### Transformar variables categóricas texto a clases numeradas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GJlDmX_F1ksA"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "df_cod = df.copy()\n",
        "df_cod['DrugY'] = df_cod['Drug'].apply(lambda x: 1 if x == 'drugY' else 0)\n",
        "df_cod = df_cod.drop('Drug', axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lqa4Qq9dEGzr"
      },
      "source": [
        "df_cod.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KKM3d-0Hp7KL"
      },
      "source": [
        "ax = sns.countplot(data=df_cod, x=\"DrugY\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-Y-eHwV08v3"
      },
      "source": [
        "def one_hot_encoding(df, column):\n",
        "    df_copy = df.copy()\n",
        "    # LabelEncoder\n",
        "    le = LabelEncoder()\n",
        "    label_encoding = le.fit_transform(df_copy[column])\n",
        "    # OneHotEncoder\n",
        "    onehot_encoder = OneHotEncoder(sparse=False)\n",
        "    one_hot_encoding = onehot_encoder.fit_transform(label_encoding.reshape(-1, 1))\n",
        "    # Crear las columnas con el resultado del encoder\n",
        "    one_hot_encoding_df = pd.DataFrame(one_hot_encoding, columns=le.classes_, dtype=int)\n",
        "    # Agregar sufijo\n",
        "    one_hot_encoding_df = one_hot_encoding_df.add_prefix(column+'_')\n",
        "    # Unir nuevas columnas al dataset\n",
        "    df_copy = df_copy.join(one_hot_encoding_df)\n",
        "    # Eleminar vieja columna del dataset\n",
        "    df_copy = df_copy.drop([column], axis=1)\n",
        "    return df_copy\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-mXf8mxK2qps"
      },
      "source": [
        "df_cod = one_hot_encoding(df_cod, 'Sex')\n",
        "df_cod = one_hot_encoding(df_cod, 'BP')\n",
        "df_cod = one_hot_encoding(df_cod, 'Cholesterol')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JcMF3cQq3NHC"
      },
      "source": [
        "df_cod.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nnTURxKwNMgV"
      },
      "source": [
        "sns.displot(data=df_cod, x='Age')\n",
        "sns.displot(data=df_cod, x='Na_to_K')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IyIzTou_N5S_"
      },
      "source": [
        "# Es importante normalizar los datos, ya que las redes funcionan con el proceso\n",
        "# del gradiente descendente.\n",
        "# Como \"Age\" no sigue una distribucion normal y \"Na_to_K\" no parece tener outliers\n",
        "# utilizaremos el MinMaxScaler\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "df_norm = df_cod.copy()\n",
        "df_norm.loc[:, 'Age'] = scaler.fit_transform(df_norm[['Age']])\n",
        "df_norm.loc[:, 'Na_to_K'] = scaler.fit_transform(df_norm[['Na_to_K']])\n",
        "df_norm.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7z_SuZlj3gbQ"
      },
      "source": [
        "# Entrenar modelo\n",
        "<img src=\"https://raw.githubusercontent.com/InoveAlumnos/dataset_analytics_python/master/images/Pipeline4.png\" width=\"1000\" align=\"middle\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ntY84fHj3q5q"
      },
      "source": [
        "El primer paso es obtener los datos que serán la entrada del sistema (X) y los datos que serán la salida del modelo estimador (y)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EIg2_OQ43fqZ"
      },
      "source": [
        "X = df_norm.drop('DrugY', axis=1).values\n",
        "y = df_norm['DrugY'].values\n",
        "in_shape = X.shape[1]\n",
        "out_shape = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sbr-SnON4LuM"
      },
      "source": [
        "Siguiente paso es dividir el dataset en entrenamiento (train) y evaluación (test). Utilizaremos el criterio 80%20%"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BVD4YkjS4MW2"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "# Fijamos un \"random_state\" constante para que siempre el dataset se parta de la misma forma\n",
        "# para poder repetir los ensayos\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4jEl5aRW-Ug"
      },
      "source": [
        "from keras.layers import Dense\n",
        "\n",
        "def create_model(in_shape, hidden_neurons, out_shape):\n",
        "    # Crear un modelo secuencial\n",
        "    model = Sequential()\n",
        "\n",
        "    # Crear la capa de entrada y la capa oculta (hidden) de la red, que tendrá:\n",
        "    # --> tantas entradas (in_shape) como columnas\n",
        "    # --> tantas neuronas como deseemos\n",
        "    # --> utilizamos \"sigmoid\" como capa de activación\n",
        "    model.add(Dense(units=hidden_neurons, activation='sigmoid', input_shape=(in_shape,)))\n",
        "\n",
        "    # Crear la capa de salida, que tendrá tantas neuronas como salidas posibles\n",
        "    model.add(Dense(units=out_shape, activation='sigmoid'))\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tVMeyIyIXgfI"
      },
      "source": [
        "model = create_model(in_shape, 64, out_shape)\n",
        "\n",
        "model.compile(optimizer=\"adam\",\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(X_train, y_train, validation_split=0.2 , epochs=100, batch_size=32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kkb1Zw-ac_S9"
      },
      "source": [
        "epoch_count = range(1, len(history.history['accuracy']) + 1)\n",
        "sns.lineplot(x=epoch_count,  y=history.history['accuracy'], label='train')\n",
        "sns.lineplot(x=epoch_count,  y=history.history['val_accuracy'], label='valid')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P99GMrH-dles"
      },
      "source": [
        "y_hat_prob = model.predict(X_test)\n",
        "y_hat = [1 if x >= 0.5 else 0 for x in y_hat_prob]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m0Bmczmddm--"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w3IfjUuI4XnD"
      },
      "source": [
        "# Validar modelo\n",
        "<img src=\"https://raw.githubusercontent.com/InoveAlumnos/dataset_analytics_python/master/images/Pipeline5.png\" width=\"1000\" align=\"middle\">"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tzBGdQS67eAq"
      },
      "source": [
        "# Calcular la exactitud (accuracy)\n",
        "scores = model.evaluate(X_test, y_test)\n",
        "scores[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CMKONtv55zL8"
      },
      "source": [
        "# Calcular la exactitud (accuracy)\n",
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_score(y_test, y_hat, normalize=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TeLeYLYz6ZhO"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "cm = confusion_matrix(y_test, y_hat)\n",
        "cmd = ConfusionMatrixDisplay(cm, display_labels=['NOT_Y', 'Y'])\n",
        "cmd.plot(cmap=plt.cm.Blues)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}